{
  "": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 4
  },
  "action_show_projects": {
    "precision": 0.42857142857142855,
    "recall": 1.0,
    "f1-score": 0.6,
    "support": 3
  },
  "action_project_chooser": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 2
  },
  "withdrawal_form": {
    "precision": 1.0,
    "recall": 0.5,
    "f1-score": 0.6666666666666666,
    "support": 4
  },
  "action_invest": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 2
  },
  "mood_great": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 2
  },
  "utter_ok": {
    "precision": 0.25,
    "recall": 1.0,
    "f1-score": 0.4,
    "support": 1
  },
  "[REG506-AMD001](PROJECT_CODE)": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 2
  },
  "goodbye": {
    "precision": 0.5,
    "recall": 1.0,
    "f1-score": 0.6666666666666666,
    "support": 2
  },
  "utter_cheer_up": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 3
  },
  "utter_happy": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 3
  },
  "deny": {
    "precision": 1.0,
    "recall": 0.5,
    "f1-score": 0.6666666666666666,
    "support": 2
  },
  "check_projects": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 1
  },
  "affirm": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 2
  },
  "utter_goodbye": {
    "precision": 1.0,
    "recall": 0.5,
    "f1-score": 0.6666666666666666,
    "support": 4
  },
  "invest_form": {
    "precision": 1.0,
    "recall": 0.3333333333333333,
    "f1-score": 0.5,
    "support": 3
  },
  "utter_did_that_help": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 3
  },
  "bot_challenge": {
    "precision": 0.25,
    "recall": 1.0,
    "f1-score": 0.4,
    "support": 1
  },
  "withdrawal": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 2
  },
  "action_show_balance": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 1
  },
  "utter_greet": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 10
  },
  "[10000](amount_of_money)": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 1
  },
  "utter_noworries": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 4
  },
  "inform": {
    "precision": 0.5555555555555556,
    "recall": 1.0,
    "f1-score": 0.7142857142857143,
    "support": 5
  },
  "[50000000000](amount_of_money)": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 1
  },
  "check_balance": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 1
  },
  "mood_unhappy": {
    "precision": 0.0,
    "recall": 0.0,
    "f1-score": 0.0,
    "support": 3
  },
  "[500000](amount_of_money)": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 3
  },
  "invest": {
    "precision": 0.6666666666666666,
    "recall": 1.0,
    "f1-score": 0.8,
    "support": 2
  },
  "action_listen": {
    "precision": 0.9142857142857143,
    "recall": 0.7804878048780488,
    "f1-score": 0.8421052631578947,
    "support": 41
  },
  "utter_iamabot": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 1
  },
  "greet": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 10
  },
  "utter_help": {
    "precision": 0.5,
    "recall": 1.0,
    "f1-score": 0.6666666666666666,
    "support": 5
  },
  "action_withdrawal": {
    "precision": 1.0,
    "recall": 1.0,
    "f1-score": 1.0,
    "support": 2
  },
  "thankyou": {
    "precision": 0.75,
    "recall": 0.75,
    "f1-score": 0.75,
    "support": 4
  },
  "micro avg": {
    "precision": 0.8,
    "recall": 0.7428571428571429,
    "f1-score": 0.7703703703703704,
    "support": 140
  },
  "macro avg": {
    "precision": 0.6804308390022675,
    "recall": 0.7246806039488967,
    "f1-score": 0.6668492660221984,
    "support": 140
  },
  "weighted avg": {
    "precision": 0.7634467120181406,
    "recall": 0.7428571428571429,
    "f1-score": 0.7295076978159685,
    "support": 140
  },
  "accuracy": 0.7428571428571429,
  "conversation_accuracy": {
    "accuracy": 0.23076923076923078,
    "correct": 3,
    "with_warnings": 0,
    "total": 13
  }
}